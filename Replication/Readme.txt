General information
====================

Here we provide a collection of java executables, bash scripts and R scripts that can be used to replicate the simulations carried out 
for the paper 'R&D location strategies' authored by Luca Colombo, Herbert Dawid and Philipp Harting. I

In particular, we provide everything what is needed to replicate 
the industry analysis outlined in Section 4 and the strategy analysis in Section 5. Note that this collection as-is can only be used under certain specific system requirements. 
In particular, you will need a Linux system (e.g. Ubuntu) as the bash scripts that manage the flow of jobs can only be interpreted by Linux. If no Linux system is available, there are essentially two possibilities: 
Either you translate the bash syntax in the corresponding syntax for MS or Mac, or you download a Virtual Machine that hosts a Linux distribution.   

=======================
System requirements:
============================
-Linux
-R including the packages: RSQLite, mlogit,
- preferable: a multi core machine with as many cores as possible 


NOTE: In the following, we always use relative path, where ./Replication is the top level folder. If you run the R scripts, you have to launch them from this folder!

=================
Replicating the Industry analysis 
=================

The industry analysis can be found in section 4 of the paper.

1. Run the simulation:

In order to run the simulations, one has to launch the bash file run_exp_industry.sh from the console (use command bash run_exp_industry.sh). The parameters defined in the 
bash script correspond to those used in the paper. If you want to change specific parameters, you can change or add further ones in lines 42-64 of the file.

Default settings: 1000 iterations, 200 batch runs, 1 processor

These settings can also be changed in the run_exp_industry.sh file.

After launching, the bash script will call two other bash scripts (exp_script_1.sh and exp_script_2.sh), who will generate a folder structure with its_industry as the top level folder. In this folder structure, the data bases 
of each simulation run are written.

Note: The default setting  implies that all 200 batch runs are executed sequentially on one core. Depending on the model settings, the CPU time of a single run can be up to 5-10 minutes. 
Running batch runs sequentially implies only for the baseline setting wall time of up to 33h. Therefore, it is highly recommended to run the simulations on a multi core machine. If you have a computer with X cores, 
you can change the line export NUM_PROCS=1 to export NUM_PROCS=X in the run_exp_industry.sh. As a consequence, the wall time will be reduced by 33h/X.

Further note that the default setting requires 450 MB hard disk space.


2. Processing the data:

Here you can find three r scripts,
- table1_2.r
- table1_3.r
- table1_4.r
which can directly generate Table 2 -4 from the data generated in step 1. Note that if you have changed some of the settings (e.g. the number of batch runs, the parameters that define the folder structure) you
have to adjust the r scripts. To start one of the scripts, open R from the console and start the script by using
source().
The output is printed on the console.


Furthermore, there is a R script r_getdata_as dataframe.r which features three functions that can be used to retrieve the data for Firms, Locations, and AggegatedData for further analysis. The data is returned as an R data frame, further 
analysis can be carried out with standard R data frame operations. 



=================
Replicating the Industry analysis 
=================

1. Run the simulation:

To run the simulations with the standard settings used in section 5 of the paper, execute the bash script run_exp_strat.sh from the console. It should be noted that the simulations for the strategy analysis are quite heavy and take 
a lot of CPU time. (We run 19x4x200 = 15200 runs for the different industry scenarios and strategy parameter constellations!!!) Therefore, it is highly recommended to run this experiments on a multi core system with as many cores/ CPUs as possible!

Alternatively, one can reduce the simulations and could only consider, e.g., three values of the strategy parameter -0.15, 0.0, and 0.3. using again 200 batch runs, one would have 2400 runs, which still requires 400h CPU time. 


2. Processing the data:
 
Plots shown in section 5 of the paper can be generated by running the R script r_strategy.r The plots are written as pdf in a folder figs_strategy. Again, the r_script is set up to generate the plots given the standard setting. if one wants to change the set up, the r script
has to be adjusted accordingly. 

Here, we also have the possibility to run this R script in a parallel model, which might speed up the analysis substantially. Depending on the number of cores available, one can change the nubmber of cores (mc.core ) in line 3819 (DATA = mclapply(pararray, get_data_parallel_exit_entry, mc.cores =1)).
 

